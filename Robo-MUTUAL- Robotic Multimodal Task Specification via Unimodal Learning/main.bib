
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Representation Learning %%

@inproceedings{ma2023liv,
  title={Liv: Language-image representations and rewards for robotic control},
  author={Ma, Yecheng Jason and Kumar, Vikash and Zhang, Amy and Bastani, Osbert and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={23301--23320},
  year={2023},
  organization={PMLR}
}

@article{nair2022r3m,
  title={R3m: A universal visual representation for robot manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2203.12601},
  year={2022}
}

@inproceedings{nair2022lorel,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea and others},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}

@article{karamcheti2023voltron,
  title={Language-driven representation learning for robotics},
  author={Karamcheti, Siddharth and Nair, Suraj and Chen, Annie S and Kollar, Thomas and Finn, Chelsea and Sadigh, Dorsa and Liang, Percy},
  journal={arXiv preprint arXiv:2302.12766},
  year={2023}
}

@inproceedings{li2024decisionnce,
  title={DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning},
  author={Li, Jianxiong and Zheng, Jinliang and Zheng, Yinan and Mao, Liyuan and Hu, Xiao and Cheng, Sijie and Niu, Haoyi and Liu, Jihao and Liu, Yu and Liu, Jingjing and others},
  booktitle={Forty-first International Conference on Machine Learning}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Innate Multimodal Integration in the Brain %%
@article{zhao2024eye,
  title={Eye-brain connections revealed by multimodal retinal and brain imaging genetics},
  author={Zhao, Bingxin and Li, Yujue and Fan, Zirui and Wu, Zhenyi and Shu, Juan and Yang, Xiaochen and Yang, Yilin and Wang, Xifeng and Li, Bingxuan and Wang, Xiyao and others},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={6064},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{denervaud2020multisensory,
  title={Multisensory gains in simple detection predict global cognition in schoolchildren},
  author={Denervaud, Solange and Gentaz, Edouard and Matusz, Pawel J and Murray, Micah M},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1394},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{burr2012multisensory,
  title={Multisensory integration develops late in humans},
  author={Burr, David and Gori, Monica},
  year={2012}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Multi-modal Task Specification %%

@inproceedings{shah2023mutex,
title        = {MUTEX: Learning Unified Policies from Multimodal Task Specifications},
author       = {Rutav Shah and Roberto Mart{\'\i}n-Mart{\'\i}n and Yuke Zhu},
year         = 2023,
booktitle    = {7th Annual Conference on Robot Learning},
url          = {https://openreview.net/forum?id=PwqiqaaEzJ}
}

@inproceedings{jiang2023vima,
  title     = {VIMA: General Robot Manipulation with Multimodal Prompts},
  author    = {Yunfan Jiang and Agrim Gupta and Zichen Zhang and Guanzhi Wang and Yongqiang Dou and Yanjun Chen and Li Fei-Fei and Anima Anandkumar and Yuke Zhu and Linxi Fan},
  booktitle = {Fortieth International Conference on Machine Learning},
  year      = {2023}
}

@inproceedings{driess2023palme,
    title={PaLM-E: An Embodied Multimodal Language Model},
    author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi S. M. and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and Chebotar, Yevgen and Sermanet, Pierre and Duckworth, Daniel and Levine, Sergey and Vanhoucke, Vincent and Hausman, Karol and Toussaint, Marc and Greff, Klaus and Zeng, Andy and Mordatch, Igor and Florence, Pete},
    booktitle={arXiv preprint arXiv:2303.03378},
    year={2023}
}

@inproceedings{myers2023goal,
  title={Goal representations for instruction following: A semi-supervised language interface to control},
  author={Myers, Vivek and He, Andre Wang and Fang, Kuan and Walke, Homer Rich and Hansen-Estruch, Philippe and Cheng, Ching-An and Jalobeanu, Mihai and Kolobov, Andrey and Dragan, Anca and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={3894--3908},
  year={2023},
  organization={PMLR}
}


@inproceedings{yu2023using,
title={Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks},
author={Albert Yu and Ray Mooney},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=4u42KCQxCn8}
}

@inproceedings{octo_2023,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}

@inproceedings{reuss2024multimodal,
  title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
  author={Reuss, Moritz and Ya{\u{g}}murlu, {\"O}mer Erdin{\c{c}} and Wenzel, Fabian and Lioutikov, Rudolf},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Dataset %%

@inproceedings{walke2023bridgedata,
    title={BridgeData V2: A Dataset for Robot Learning at Scale},
    author={Walke, Homer and Black, Kevin and Lee, Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch, Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn, Chelsea and Levine, Sergey},
    booktitle={Conference on Robot Learning (CoRL)},
    year={2023}
}

@inproceedings{damen2018epick,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={720--736},
  year={2018}
}

@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5842--5850},
  year={2017}
}

@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@article{padalkar2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={Padalkar, Abhishek and Pooley, Acorn and Jain, Ajinkya and Bewley, Alex and Herzog, Alex and Irpan, Alex and Khazatsky, Alexander and Rai, Anant and Singh, Anikait and Brohan, Anthony and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Components %%

@inproceedings{blank2024scaling,
  title={Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models},
  author={Blank, Nils and Reuss, Moritz and Wenzel, Fabian and Mees, Oier and Lioutikov, Rudolf},
  booktitle={2nd Workshop on Mobile Manipulation and Embodied Intelligence at ICRA 2024},
  year={2024}
}

@inproceedings{xiao2022dial,
  title={Robotic Skill Acquistion via Instruction Augmentation with Vision-Language Models},
  author={Xiao, Ted and Chan, Harris and Sermanet, Pierre and Wahid, Ayzaan and Brohan, Anthony and Hausman, Karol and Levine, Sergey and Tompson, Jonathan},
  booktitle={Proceedings of Robotics: Science and Systems},
  year={2023}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Modality Gap %%

@INPROCEEDINGS{lafite,
  author={Zhou, Yufan and Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Tensmeyer, Chris and Yu, Tong and Gu, Jiuxiang and Xu, Jinhui and Sun, Tong},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Towards Language-Free Training for Text-to-Image Generation}, 
  year={2022},
  volume={},
  number={},
  pages={17886-17896},
  keywords={Training;Image synthesis;Semantics;Training data;Tail;Data collection;Data models;Vision + language; Image and video synthesis and generation},
  doi={10.1109/CVPR52688.2022.01738}}


@article{huh2024platonic,
  title={The platonic representation hypothesis},
  author={Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
  journal={arXiv preprint arXiv:2405.07987},
  year={2024}
}

@article{zhang2024connect,
  title={Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data},
  author={Zhang, Yuhui and Sui, Elaine and Yeung-Levy, Serena},
  journal={arXiv preprint arXiv:2401.08567},
  year={2024}
}

@article{liang2022mind,
  title={Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning},
  author={Liang, Victor Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James Y},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17612--17625},
  year={2022}
}

@inproceedings{shi2023towards,
  title={Towards understanding the modality gap in CLIP},
  author={Shi, Peiyang and Welle, Michael C and Bj{\"o}rkman, M{\aa}rten and Kragic, Danica},
  booktitle={ICLR 2023 Workshop on Multimodal Representation Learning: Perks and Pitfalls},
  year={2023}
}

@inproceedings{
  zhang2023diagnosing,
  title={Diagnosing and Rectifying Vision Models using Language},
  author={Zhang, Yuhui and HaoChen, Jeff Z and Huang, Shih-Cheng and Wang, Kuan-Chieh and Zou, James and Yeung, Serena},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://openreview.net/pdf?id=D-zfUK7BR6c}
}

@article{li2023decap,
  title={Decap: Decoding clip latents for zero-shot captioning via text-only training},
  author={Li, Wei and Zhu, Linchao and Wen, Longyin and Yang, Yi},
  journal={arXiv preprint arXiv:2303.03032},
  year={2023}
}

@article{nukrai2022capdec,
  title={Text-only training for image captioning using noise-injected clip},
  author={Nukrai, David and Mokady, Ron and Globerson, Amir},
  journal={arXiv preprint arXiv:2211.00575},
  year={2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Used Modules (kins of networks) %%

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Environments %%

@article{liu2024libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LCBC %%

@article{brohan2022rt1,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}

@article{brohan2023rt2,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}



@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{zhou2023language,
  title={Language-conditioned learning for robotic manipulation: A survey},
  author={Zhou, Hongkuan and Yao, Xiangtong and Meng, Yuan and Sun, Siming and BIng, Zhenshan and Huang, Kai and Knoll, Alois},
  journal={arXiv preprint arXiv:2312.10807},
  year={2023}
}

@article{xiao2022robotic,
  title={Robotic skill acquisition via instruction augmentation with vision-language models},
  author={Xiao, Ted and Chan, Harris and Sermanet, Pierre and Wahid, Ayzaan and Brohan, Anthony and Hausman, Karol and Levine, Sergey and Tompson, Jonathan},
  journal={arXiv preprint arXiv:2211.11736},
  year={2022}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Image Caption %%
@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{zhou2022lafite2,
  title={Lafite2: Few-shot text-to-image generation},
  author={Zhou, Yufan and Li, Chunyuan and Chen, Changyou and Gao, Jianfeng and Xu, Jinhui},
  journal={arXiv preprint arXiv:2210.14124},
  year={2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Video Caption %%

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{ventura2024learning,
  title={Learning text-to-video retrieval from image captioning},
  author={Ventura, Lucas and Schmid, Cordelia and Varol, G{\"u}l},
  journal={arXiv preprint arXiv:2404.17498},
  year={2024}
}


@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@inproceedings{gu2023text,
  title={Text with knowledge graph augmented transformer for video captioning},
  author={Gu, Xin and Chen, Guang and Wang, Yufei and Zhang, Libo and Luo, Tiejian and Wen, Longyin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18941--18951},
  year={2023}
}

@inproceedings{tang2021clip4caption,
  title={Clip4caption: Clip for video caption},
  author={Tang, Mingkang and Wang, Zhanyu and Liu, Zhenhua and Rao, Fengyun and Li, Dian and Li, Xiu},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={4858--4862},
  year={2021}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{islam2024gpt,
  title={GPT-4o: The Cutting-Edge Advancement in Multimodal LLM},
  author={Islam, Raisa and Moushi, Owana Marzia},
  journal={Authorea Preprints},
  year={2024},
  publisher={Authorea}
}

@inproceedings{shi2019dense,
  title={Dense procedure captioning in narrated instructional videos},
  author={Shi, Botian and Ji, Lei and Liang, Yaobo and Duan, Nan and Chen, Peng and Niu, Zhendong and Zhou, Ming},
  booktitle={Proceedings of the 57th annual meeting of the association for computational linguistics},
  pages={6382--6391},
  year={2019}
}

@inproceedings{ryu2021semantic,
  title={Semantic grouping network for video captioning},
  author={Ryu, Hobin and Kang, Sunghun and Kang, Haeyong and Yoo, Chang D},
  booktitle={proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={3},
  pages={2514--2522},
  year={2021}
}

@inproceedings{nguyen2021practical,
  title={Practical cross-modal manifold alignment for robotic grounded language learning},
  author={Nguyen, Andre T and Richards, Luke E and Kebe, Gaoussou Youssouf and Raff, Edward and Darvish, Kasra and Ferraro, Frank and Matuszek, Cynthia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1613--1622},
  year={2021}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% cosine noise %%

@article{liu2024arcsin,
  title={ArcSin: Adaptive ranged cosine Similarity injected noise for Language-Driven Visual Tasks},
  author={Liu, Yang and Yu, Xiaomin and Zhang, Gongyu and Bergeles, Christos and Dasgupta, Prokar and Granados, Alejandro and Ourselin, Sebastien},
  journal={arXiv preprint arXiv:2402.17298},
  year={2024}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{rahmatizadeh2018vision,
  title={Vision-based multi-task manipulation for inexpensive robots using end-to-end learning from demonstration},
  author={Rahmatizadeh, Rouhollah and Abolghasemi, Pooya and B{\"o}l{\"o}ni, Ladislau and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3758--3765},
  year={2018},
  organization={IEEE}
}

@article{sun2022paco,
  title={Paco: Parameter-compositional multi-task reinforcement learning},
  author={Sun, Lingfeng and Zhang, Haichao and Xu, Wei and Tomizuka, Masayoshi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21495--21507},
  year={2022}
}

@inproceedings{jang2022bc,
  title={Bc-z: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2022},
  organization={PMLR}}

@inproceedings{
ma2023vip,
title={{VIP}: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training},
author={Yecheng Jason Ma and Shagun Sodhani and Dinesh Jayaraman and Osbert Bastani and Vikash Kumar and Amy Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=YJ7o2wetJ2}
}


@article{belkhale2024rt,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{cui2022can,
  title={Can foundation models perform zero-shot task specification for robot manipulation?},
  author={Cui, Yuchen and Niekum, Scott and Gupta, Abhinav and Kumar, Vikash and Rajeswaran, Aravind},
  booktitle={Learning for dynamics and control conference},
  pages={893--905},
  year={2022},
  organization={PMLR}
}


@inproceedings{
cui2023from,
title={From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data},
author={Zichen Jeff Cui and Yibin Wang and Nur Muhammad Mahi Shafiullah and Lerrel Pinto},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=c7rM7F7jQjN}
}

@article{yu2018one,
  title={One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  author={Yu, Tianhe and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal={Robotics: Science and Systems XIV},
  year={2018},
  publisher={Robotics: Science and Systems Foundation}
}


@article{bonardi2020learning,
  title={Learning one-shot imitation from humans without humans},
  author={Bonardi, Alessandro and James, Stephen and Davison, Andrew J},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={3533--3539},
  year={2020},
  publisher={IEEE}
}

@inproceedings{james2018task,
  title={Task-embedded control networks for few-shot imitation learning},
  author={James, Stephen and Bloesch, Michael and Davison, Andrew J},
  booktitle={Conference on robot learning},
  pages={783--795},
  year={2018},
  organization={PMLR}
}

@article{shi2024yell,
  title={Yell at your robot: Improving on-the-fly from language corrections},
  author={Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.12910},
  year={2024}
}

@article{lynch2020language,
  title={Language conditioned imitation learning over unstructured data},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}

@article{mees2022matters,
  title={What matters in language conditioned robotic imitation learning over unstructured data},
  author={Mees, Oier and Hermann, Lukas and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={11205--11212},
  year={2022},
  publisher={IEEE}
}


@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}




@inproceedings{khandelwal2022simple,
  title={Simple but effective: Clip embeddings for embodied ai},
  author={Khandelwal, Apoorv and Weihs, Luca and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14829--14838},
  year={2022}
}

@inproceedings{
jing2022understanding,
title={Understanding Dimensional Collapse in Contrastive Self-supervised Learning},
author={Li Jing and Pascal Vincent and Yann LeCun and Yuandong Tian},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=YevsQ05DEN7}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}


@inproceedings{
schrodi2024two,
title={Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Representation Learning},
author={Simon Schrodi and David T Hoffmann and Max Argus and Volker Fischer and Thomas Brox},
booktitle={ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models},
year={2024},
url={https://openreview.net/forum?id=7QwFMLzQHH}
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{hansen2023idql,
  title={Idql: Implicit q-learning as an actor-critic method with diffusion policies},
  author={Hansen-Estruch, Philippe and Kostrikov, Ilya and Janner, Michael and Kuba, Jakub Grudzien and Levine, Sergey},
  journal={arXiv preprint arXiv:2304.10573},
  year={2023}
}



@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@article{zheng2024safe,
  title={Safe offline reinforcement learning with feasibility-guided diffusion model},
  author={Zheng, Yinan and Li, Jianxiong and Yu, Dongjie and Yang, Yujie and Li, Shengbo Eben and Zhan, Xianyuan and Liu, Jingjing},
  journal={arXiv preprint arXiv:2401.10700},
  year={2024}
}


@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  journal={arXiv preprint arXiv:2303.04137},
  year={2023}
}


@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@inproceedings{mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}


@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@inproceedings{
li2023mind,
title={Mind the Gap: Offline Policy Optimization for Imperfect Rewards},
author={Jianxiong Li and Xiao Hu and Haoran Xu and Jingjing Liu and Xianyuan Zhan and Qing-Shan Jia and Ya-Qin Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WumysvcMvV6}
}

@article{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}