\mysection{Conclusion and Limitations}
This paper introduces \lb{}, a new benchmark in the robot manipulation domain for supporting research in \lldm{}. \lb{} includes a procedural generation pipeline that can create an infinite number of manipulation tasks in the simulator. We use this pipeline to create 130 standardized tasks and conduct a comprehensive set of experiments on policy and algorithm designs. The empirical results suggest several future research directions: 1) how to design a better neural architecture to better process spatial information or temporal information; 2) how to design a better algorithm to improve forward transfer ability; and 3) how to use pretraining to help improve lifelong learning performance.
% All experiments reported in this paper use imitation learning.  While \lb{} is designed to support research on RL for \lldm{}, we leave this direction for future research due to the computational and data demands of applying RL within \lb{}. 
In the short term, we do not envision any negative societal impacts triggered by \lb{}. But as the lifelong learner mainly learns from humans, studying how to preserve user privacy within \lldm{}~\citep{Liu2022ContinualLA} is crucial in the long run.
% We have yet to investigate RL in \lldm{} because of the limited computation resource and the challenge in sparse-reward RL. But this can be an interesting future direction.